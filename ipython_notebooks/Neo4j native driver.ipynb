{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "creator": "admin",
    "createdOn": 1650550745143,
    "tags": [],
    "customFields": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport dataiku.spark as dkuspark\nimport pyspark\nfrom pyspark.sql import SQLContext"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load PySpark\nsc \u003d pyspark.SparkContext()\nsqlContext \u003d SQLContext(sc)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: Read the descriptor of a Dataiku dataset\nmydataset \u003d dataiku.Dataset(\"mydataset\")\n# And read it as a Spark dataframe\ndf \u003d dkuspark.get_dataframe(sqlContext, mydataset)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: Get the count of records in the dataframe\n",
        "df.count()"
      ],
      "outputs": []
    }
  ]
}